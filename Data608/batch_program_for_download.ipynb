{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ryan Leeson, Keith Jennings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting download2.py\n"
     ]
    }
   ],
   "source": [
    "%%file download2.py\n",
    "\n",
    "import sys, os, time\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "files_to_download = []\n",
    "\n",
    "with open ('amazon_reviews.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        files_to_download.append (line.strip ())\n",
    "\n",
    "\n",
    "\n",
    "def download_file (url):\n",
    "    \n",
    "    file_name = 'Files/' + url.split ('categoryFilesSmall/')[1]\n",
    "\n",
    "    if os.path.exists (file_name) and not forced:\n",
    "        print (f' - {file_name} already exists')\n",
    "        return\n",
    "    print (f' - {file_name} downloading')\n",
    "    urllib.request.urlretrieve (url, file_name)\n",
    "    \n",
    "    \n",
    "def download (files, ncpus, func, force = False):\n",
    "    \n",
    "    global forced\n",
    "    forced = force\n",
    "    \n",
    "    with ThreadPool (processes = ncpus) as pool:\n",
    "        pool.map (func, files)\n",
    "            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    force_or_not = sys.argv[1]\n",
    "    ncpus = int (os.environ[\"SLURM_CPUS_ON_NODE\"])\n",
    "    start = time.time ()\n",
    "    download (files_to_download, ncpus, download_file, force_or_not)\n",
    "    print (f'Download was {time.time () - start:.3f} s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting download2.script\n"
     ]
    }
   ],
   "source": [
    "%%file download2.script\n",
    "#!/bin/bash\n",
    "#SBATCH --time=01:30:0\n",
    "#SBATCH -N 1\n",
    "#SBATCH -n 15\n",
    "\n",
    "module load python/anaconda-3.6-5.1.0\n",
    "python download2.py False\n",
    "\n",
    "\n",
    "#   I don't know why, but with these settings downloaded the files in about 50 minutes.\n",
    "#   More nodes and more cores didn't seem to improve the outcome. Even a job set for 1h10m didn't finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wget_files/parallel_wget.script\n"
     ]
    }
   ],
   "source": [
    "#   Alternative program to download the json files.\n",
    "\n",
    "%%file wget_files/parallel_wget.script\n",
    "#!/bin/bash\n",
    "#SBATCH --time=0:30:0\n",
    "#SBATCH -N 1\n",
    "#SBATCH -n 24\n",
    "\n",
    "cat amazon_reviews.txt | xargs -n 1 -P 24 wget -q\n",
    "\n",
    "###   Using wget in parallel was not any better than using a slurm job with urllib.request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The download took about 50 minutes to complete. The output of the job is in 'slurm-6308.out'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Files/AMAZON_FASHION_5.json.gz downloading\r\n",
      " - Files/Electronics_5.json.gz downloading\r\n",
      " - Files/Gift_Cards_5.json.gz downloading\r\n",
      " - Files/Grocery_and_Gourmet_Food_5.json.gz downloading\r\n",
      " - Files/All_Beauty_5.json.gz downloading\r\n",
      " - Files/Home_and_Kitchen_5.json.gz downloading\r\n",
      " - Files/Industrial_and_Scientific_5.json.gz downloading\r\n",
      " - Files/Appliances_5.json.gz downloading\r\n",
      " - Files/Arts_Crafts_and_Sewing_5.json.gz downloading\r\n",
      " - Files/Automotive_5.json.gz downloading\r\n",
      " - Files/Books_5.json.gz downloading\r\n",
      " - Files/CDs_and_Vinyl_5.json.gz downloading\r\n",
      " - Files/Cell_Phones_and_Accessories_5.json.gz downloading\r\n",
      " - Files/Clothing_Shoes_and_Jewelry_5.json.gz downloading\r\n",
      " - Files/Digital_Music_5.json.gz downloading\r\n",
      " - Files/Kindle_Store_5.json.gz downloading\r\n",
      " - Files/Luxury_Beauty_5.json.gz downloading\r\n",
      " - Files/Magazine_Subscriptions_5.json.gz downloading\r\n",
      " - Files/Movies_and_TV_5.json.gz downloading\r\n",
      " - Files/Musical_Instruments_5.json.gz downloading\r\n",
      " - Files/Office_Products_5.json.gz downloading\r\n",
      " - Files/Patio_Lawn_and_Garden_5.json.gz downloading\r\n",
      " - Files/Pet_Supplies_5.json.gz downloading\r\n",
      " - Files/Prime_Pantry_5.json.gz downloading\r\n",
      " - Files/Software_5.json.gz downloading\r\n",
      " - Files/Sports_and_Outdoors_5.json.gz downloading\r\n",
      " - Files/Tools_and_Home_Improvement_5.json.gz downloading\r\n",
      " - Files/Toys_and_Games_5.json.gz downloading\r\n",
      " - Files/Video_Games_5.json.gz downloading\r\n",
      "Download was 3020.565 s.\r\n"
     ]
    }
   ],
   "source": [
    "! cat slurm-6308.out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
