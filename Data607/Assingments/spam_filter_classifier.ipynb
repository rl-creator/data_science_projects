{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Spam Detection with Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Write a python function that returns\n",
    "    1. the frequency of a given character in a string,\n",
    "    2. the frequency of a given word (maximal consecutive sequence of letters, case insensitive) in string,\n",
    "    3. a list of all maximal sequences of consecutive capital letters in a string,\n",
    "\n",
    "    in a string.\n",
    "\n",
    "2.  For each message in the dataset `sms_spam.csv`, compute:\n",
    "    1. the frequency of the each of the words in the list `words` defined below,\n",
    "    2. the frequency of the each of the characters in the list `chars` defined below,\n",
    "    3. the average run length of a maximal sequence of capital letters,\n",
    "    4. the longest run length of a maximal sequence of capital letters,\n",
    "    5. the sum of the run lengths of the maximal sequences of capital letters.\n",
    "    \n",
    "    \n",
    "**More precisely:**\n",
    "    \n",
    "- One can interpret *word* in a numbe of ways.\n",
    "If we interpret *word* it as a string of consecutive letters, the sentence,\n",
    "\"The reporter filed a report about reportables.\" contains three occurences of the word *report*.\n",
    "We could also interpred *word* as a string of consecutive letters, neither preceded nor followed by a letter,\n",
    "then that sentence would contain only one occurence of the work *report*.\n",
    "Choose whichever one of these interpretations your prefer. If you think of a better interpretation, feel free to use that.\n",
    "    \n",
    "- The simplest interpretation of maximal sequence of capital letters is a sequence of capital letters\n",
    "neither preceded nor followed by a capital letter.\n",
    "For example, in the string \"abcDEFGhiJKL345 MNO PQR\", \"DEFG\", \"JKL\", \"MNO\" and \"PQR\"\n",
    "are maximal sequences of capital letters while \"DEF\" \"KL\" and \"MNO PQR\" aren't.\n",
    "(The first two aren't maximal and the third doesn't consist entirely of capital letters.)\n",
    "This isn't the only interpretation. In the string \"He shouted, 'STOP SHOUTING AT ME!'\", one could argue that \"STOP SHOUTING AT ME\" should count as a single (maximal) sequence of capital letters. If you prefer such an interpretation, feel free to use it.\n",
    "    \n",
    "- These details aren't really the point. We're just trying to extract features for analysis. Any reasonable approach is fine.\n",
    "    \n",
    "3.  Arrange the results in a dataframe. The frequencies computed in 1. and 2. should go in columns named\n",
    "    `freq_<word>` and `freq_<char>`, respectively. The run lengths in 3., 4., and 5. should go in columns named\n",
    "    `capital_run_length_average`, `capital_run_length_longest`, and `capital_run_length_total`, respectively.\n",
    "    The last column in your dataframe should be the target, 1 if the target is spam and 0 if it isn't.\n",
    "    Save your dataset as a `.csv` file called `sms_spam_features.csv`.\n",
    "\n",
    "\n",
    "4.  Based on these 57 features, use a random forest tree to train a spam-detecting classifier:\n",
    "\n",
    "5.  Repeat 2. through 4. for the datasets `spambase.csv` and `spam_or_not_spam.csv`.\n",
    "\n",
    "6.  Comment on similarities/differences you notice between datasets (include our analysis of `spambase.csv`), classification methods, etc.\n",
    "\n",
    "7.  **Optional:** Construct spam detectors using other classifiers you've learned about, and compare their performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['make', 'address', 'all', '3d', 'our', 'over', 'remove', 'internet', 'order', 'mail', 'receive', 'will', 'people',\n",
    "         'report', 'addresses', 'free', 'business', 'email', 'you', 'credit', 'your', 'font', '000', 'money', 'hp', 'hpl', \n",
    "         'george', '650', 'lab', 'labs', 'telnet', '857', 'data', '415', '85', 'technology', '1999', 'parts', 'pm', 'direct',\n",
    "         'cs', 'meeting', 'original', 'project', 're', 'edu', 'table', 'conference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [';', '(', '[', '!', '$', '#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charac_freq (charac, string):\n",
    "    regex = re.compile (charac)\n",
    "    matches = regex.findall (string)\n",
    "    return len (matches) / len (string)   \n",
    "    #   return the ratio of the count of the desired character in the in the string and the total number of \n",
    "    #   characters in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13333333333333333\n",
      "0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "#   Test\n",
    "a = \"This will work!\"\n",
    "\n",
    "print (charac_freq ('i', a))\n",
    "print (charac_freq ('!', a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freq (word, string):\n",
    "    #   Because we examination in case insensitive the word and the string can be made all lower case before\n",
    "    #   applying the functions.\n",
    "    regex = re.compile (word.lower ()) \n",
    "    matches = regex.findall (string.lower ())\n",
    "    return len (matches) / len (string.split ())\n",
    "    #   return the ratio of the coun of the desired word in the string and the total number of words in the \n",
    "    #   string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09090909090909091\n",
      "0.18181818181818182\n"
     ]
    }
   ],
   "source": [
    "#   Test\n",
    "b = 'There is a lot of data to examine in Data Science.'\n",
    "\n",
    "print (word_freq ('Science', b))\n",
    "print (word_freq ('data', b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_caps (string):\n",
    "    regex = re.compile (r'[A-Z]+')   #   This will grab all strings with one or more capital letters.\n",
    "    return regex.findall (string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THIS', 'IS', 'BUSI', 'YE']\n"
     ]
    }
   ],
   "source": [
    "#   Test\n",
    "c = 'THIS IS BUSIest time of the school YEar.'\n",
    "\n",
    "print (max_caps (c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = pd.read_csv ('~/Desktop/DS607/Assignment/A3/sms_spam_cleaned.csv')\n",
    "messages.head (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = []   #   will contain lists of counts for each word in words\n",
    "\n",
    "for ind in range (len (messages)):\n",
    "    freq_i = []   #   count of each word in words per row\n",
    "    for word in words:\n",
    "        f = word_freq (word, messages.v2[ind])\n",
    "        freq_i.append (f)\n",
    "    freq_words.append (freq_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5564, 48)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array (freq_words).shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_characs = []\n",
    "\n",
    "for ind in range (len (messages)):\n",
    "    freq_c = []\n",
    "    for charac in chars:\n",
    "        charac = '\\%s' % charac\n",
    "        #   characters such as '(' and '[' have specific uses in regular expressions, so they must be converted\n",
    "        #   to '\\(' and '\\[' before being entered into the function charac_freq.\n",
    "        f = charac_freq (charac, messages.v2[ind])\n",
    "        freq_c.append (f)\n",
    "    freq_characs.append (freq_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5564, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array (freq_characs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_length = []\n",
    "\n",
    "vectoring = np.vectorize (len, otypes = [float])\n",
    "#   Applying this function will convert the strings in the array caps_message to floats equal to the length\n",
    "#   of the strings.\n",
    "\n",
    "for ind in range (len (messages)):\n",
    "    caps_message = max_caps (messages.v2[ind])\n",
    "    if len (caps_message) != 0:\n",
    "    #   If there are no capital letters, caps_message will be an empty list with length 0. The function\n",
    "    #   'vectoring' will return an empty array. Taking the mean of an empty array will return an error, so\n",
    "    #   an if statement is used to seperate out the empty lists and add zero to avg_length to indicate\n",
    "    #   there are zero capital letters.\n",
    "    #   The mean of an empty array will divide a sum of 0 by 0, giving an error.\n",
    "        mean_caps_message = vectoring (np.array (caps_message)).mean ()\n",
    "        avg_length.append (mean_caps_message)\n",
    "    else:\n",
    "        avg_length.append (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5564"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (avg_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_string = []\n",
    "\n",
    "for ind in range (len (messages)):\n",
    "    caps_message = max_caps (messages.v2[ind])\n",
    "    if len (caps_message) != 0:\n",
    "    #   The function max () does not accept empty lists, so they are seperated out. The else adds zero to\n",
    "    #   'longest_string' to indicate the message does not contain any capital letters.\n",
    "        longest = len (max (caps_message, key = len))\n",
    "        longest_string.append (longest)\n",
    "    else:\n",
    "        longest_string.append (0)   \n",
    "        #   if a string does not contain capital letters 'There are no caps' will be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5564"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (longest_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length = []\n",
    "\n",
    "vectoring = np.vectorize (len, otypes = [float])\n",
    "\n",
    "for ind in range (len (messages)):\n",
    "    caps_message = max_caps (messages.v2[ind])\n",
    "    sum_caps_message = vectoring (np.array (caps_message)).sum ()\n",
    "    total_length.append (sum_caps_message)\n",
    "\n",
    "#   The sum of an empty list is 0. Therefore, .sum () works where .mean () did not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5564"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (total_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   For the words in the list words\n",
    "\n",
    "words_f = []\n",
    "\n",
    "#   Convert the words in words to 'freq_<word>' and create a new list.\n",
    "for word in words:\n",
    "    word = 'freq_' + word\n",
    "    words_f.append (word)\n",
    "\n",
    "#   For the characters in the list chars\n",
    "    \n",
    "chars_f = []\n",
    "\n",
    "#   Convert the characters in chars to 'freq_<character>' and create a new list.\n",
    "for charac in chars:\n",
    "    charac = 'freq_' + charac\n",
    "    chars_f.append (charac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Convert freq_word to a dataframe\n",
    "param1 = pd.DataFrame (np.array (freq_words), columns = words_f)\n",
    "\n",
    "\n",
    "#   Convert freq_characs to a dataframe\n",
    "param2 = pd.DataFrame (np.array (freq_characs), columns = chars_f)\n",
    "\n",
    "\n",
    "#   Convert the lists avg_length, longest_string, and total_length to a dictionary and then to a dataframe.\n",
    "d = {'capital_run_length_average' : avg_length, 'capital_run_length_longest' : longest_string, 'capital_run_length_total' : total_length}\n",
    "\n",
    "param3 = pd.DataFrame (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5564, 57)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Full dataframe of all the attributes.\n",
    "parameters = pd.concat ([param1, param2, param3], axis = 1)\n",
    "\n",
    "parameters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq_make</th>\n",
       "      <th>freq_address</th>\n",
       "      <th>freq_all</th>\n",
       "      <th>freq_3d</th>\n",
       "      <th>freq_our</th>\n",
       "      <th>freq_over</th>\n",
       "      <th>freq_remove</th>\n",
       "      <th>freq_internet</th>\n",
       "      <th>freq_order</th>\n",
       "      <th>freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_conference</th>\n",
       "      <th>freq_;</th>\n",
       "      <th>freq_(</th>\n",
       "      <th>freq_[</th>\n",
       "      <th>freq_!</th>\n",
       "      <th>freq_$</th>\n",
       "      <th>freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   freq_make  freq_address  freq_all  freq_3d  freq_our  freq_over  \\\n",
       "0        0.0           0.0       0.0      0.0       0.0   0.000000   \n",
       "1        0.0           0.0       0.0      0.0       0.0   0.000000   \n",
       "2        0.0           0.0       0.0      0.0       0.0   0.035714   \n",
       "\n",
       "   freq_remove  freq_internet  freq_order  freq_mail  ...  freq_conference  \\\n",
       "0          0.0            0.0         0.0        0.0  ...              0.0   \n",
       "1          0.0            0.0         0.0        0.0  ...              0.0   \n",
       "2          0.0            0.0         0.0        0.0  ...              0.0   \n",
       "\n",
       "   freq_;    freq_(  freq_[  freq_!  freq_$  freq_#  \\\n",
       "0     0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "1     0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "2     0.0  0.006452     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                        1.00                           1   \n",
       "1                        1.00                           1   \n",
       "2                        1.25                           2   \n",
       "\n",
       "   capital_run_length_total  \n",
       "0                       3.0  \n",
       "1                       2.0  \n",
       "2                      10.0  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters.head (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5564, 58)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = []\n",
    "\n",
    "#   Creates a list according to the label in messages.v1. 1 is applied for 'spam' and 0 for 'ham'\n",
    "for ind in range (len (messages)):\n",
    "    if messages.v1[ind] == 'spam':\n",
    "        targets.append (1)\n",
    "    else:\n",
    "        targets.append (0)\n",
    "        \n",
    "\n",
    "#   Adds the list to the dataframe as a new column\n",
    "parameters['target'] = targets\n",
    "\n",
    "parameters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Export dataframe as 'sms_spam_features.csv'\n",
    "parameters.to_csv ('~/Desktop/DS607/Assignment/A3/sms_spam_features.csv', header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5564, 57) (5564,)\n"
     ]
    }
   ],
   "source": [
    "X = parameters.iloc [:,0:57]\n",
    "y = parameters.iloc [:,57]\n",
    "\n",
    "print (X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split (X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = RandomForestClassifier ()\n",
    "M.fit (X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9685534591194969"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = M.predict (X_te)\n",
    "\n",
    "accuracy_score (y_te, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parts 2-4 using 'spambase.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 58)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase = pd.read_csv ('~/Desktop/DS607/Assignment/A3/spambase.csv')\n",
    "\n",
    "spambase.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "\n",
       "   capital_run_length_total  target  \n",
       "0                       278       1  \n",
       "1                      1028       1  \n",
       "2                      2259       1  \n",
       "\n",
       "[3 rows x 58 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase.head (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Export dataframe as 'spambase_features.csv'\n",
    "spambase.to_csv ('~/Desktop/DS607/Assignment/A3/spambase_features.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 57) (4601,)\n"
     ]
    }
   ],
   "source": [
    "X2 = spambase.iloc [:, :57]\n",
    "y2 = spambase.iloc [:, 57]\n",
    "\n",
    "print (X2.shape, y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_tr, X2_te, y2_tr, y2_te = train_test_split (X2, y2, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2 = RandomForestClassifier ()\n",
    "M2.fit (X2_tr, y2_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9587404994571118"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_pred = M2.predict (X2_te)\n",
    "\n",
    "accuracy_score (y2_te, y2_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parts 2-4 using 'spam_or_not_spam.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_or_not = pd.read_csv ('~/Desktop/DS607/Assignment/A3/spam_or_not_spam.csv')\n",
    "\n",
    "spam_or_not.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>martin a posted tassos papadopoulos the greek ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>man threatens explosion in moscow thursday aug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>klez the virus that won t die already the most...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  label\n",
       "0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n",
       "1  martin a posted tassos papadopoulos the greek ...      0\n",
       "2  man threatens explosion in moscow thursday aug...      0\n",
       "3  klez the virus that won t die already the most...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_or_not.head (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2996</td>\n",
       "      <td>hyperlink hyperlink hyperlink let mortgage le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2997</td>\n",
       "      <td>thank you for shopping with us gifts for all ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2998</td>\n",
       "      <td>the famous ebay marketing e course learn to s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2999</td>\n",
       "      <td>hello this is chinese traditional 子 件 NUMBER世...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  email  label\n",
       "2996   hyperlink hyperlink hyperlink let mortgage le...      1\n",
       "2997   thank you for shopping with us gifts for all ...      1\n",
       "2998   the famous ebay marketing e course learn to s...      1\n",
       "2999   hello this is chinese traditional 子 件 NUMBER世...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_or_not.tail (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2806\n",
      "2828\n",
      "2966\n"
     ]
    }
   ],
   "source": [
    "for ind in range (len (spam_or_not)):\n",
    "    test_message = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            f = word_freq (word, spam_or_not.email[ind])\n",
    "        except:\n",
    "            print (ind)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email     \n",
      "label    1\n",
      "Name: 2806, dtype: object\n",
      "email     \n",
      "label    1\n",
      "Name: 2828, dtype: object\n",
      "email    NaN\n",
      "label      1\n",
      "Name: 2966, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (spam_or_not.loc[2806])\n",
    "print (spam_or_not.loc[2828])\n",
    "print (spam_or_not.loc[2966])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words2 = []\n",
    "\n",
    "for ind in range (len (spam_or_not)):\n",
    "    freq_i = []\n",
    "    for word in words:\n",
    "        try:\n",
    "        #   There is an NaN at the 2967th row (row 2966) and causes word_freq to return an error. So, a try \n",
    "        #   statement is used to bypass the issue and add an NaN to freq_words2.\n",
    "            f = word_freq (word, spam_or_not.email[ind])\n",
    "            freq_i.append (f)\n",
    "        except:\n",
    "            freq_i.append (np.nan)\n",
    "    freq_words2.append (freq_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 48)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array (freq_words2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_characs2 = []\n",
    "\n",
    "for ind in range (len (spam_or_not)):\n",
    "    freq_c = []\n",
    "    for charac in chars:\n",
    "        try:\n",
    "            charac = '\\%s' % charac\n",
    "            f = charac_freq (charac, spam_or_not.email[ind])\n",
    "            freq_c.append (f)\n",
    "        except:\n",
    "            freq_c.append (np.nan)\n",
    "    freq_characs2.append (freq_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 6)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array (freq_characs2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_length2 = []\n",
    "\n",
    "vectoring = np.vectorize (len, otypes = [float])\n",
    "\n",
    "for ind in range (len (spam_or_not)):\n",
    "    try:\n",
    "        caps_message = max_caps (spam_or_not.email[ind])\n",
    "        if len (caps_message) != 0:\n",
    "            mean_caps_message = vectoring (np.array (caps_message)).mean ()\n",
    "            avg_length2.append (mean_caps_message)\n",
    "        else:\n",
    "            avg_length2.append (0)\n",
    "    except:\n",
    "        avg_length2.append (np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (avg_length2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_string2 = []\n",
    "\n",
    "for ind in range (len (spam_or_not)):\n",
    "    try:\n",
    "        caps_message = max_caps (spam_or_not.email[ind])\n",
    "        if len (caps_message) != 0:\n",
    "            longest = len (max (caps_message, key = len))\n",
    "            longest_string2.append (longest)\n",
    "        else:\n",
    "            longest_string2.append (0)\n",
    "    except:\n",
    "        longest_string2.append (np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (longest_string2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length2 = []\n",
    "\n",
    "vectoring = np.vectorize (len, otypes = [float])\n",
    "\n",
    "for ind in range (len (spam_or_not)):\n",
    "    try:\n",
    "        caps_message = max_caps (spam_or_not.email[ind])\n",
    "        sum_caps_message = vectoring (np.array (caps_message)).sum ()\n",
    "        total_length2.append (sum_caps_message)\n",
    "    except:\n",
    "        total_length2.append (np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (total_length2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 57)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param1_2 = pd.DataFrame (np.array (freq_words2), columns = words_f)\n",
    "\n",
    "param2_2 = pd.DataFrame (np.array (freq_characs2), columns = chars_f)\n",
    "\n",
    "d2 = {'capital_run_length_average' : avg_length2, 'capital_run_length_longest' : longest_string2, 'capital_run_length_total' : total_length2}\n",
    "param3_2 = pd.DataFrame (d2)\n",
    "\n",
    "parameters2 = pd.concat ([param1_2, param2_2, param3_2], axis = 1)\n",
    "\n",
    "parameters2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 58)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters2['target'] = spam_or_not['label']\n",
    "\n",
    "parameters2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Export dataframe as 'spam_or_not_spam_features.csv'\n",
    "parameters2.to_csv ('~/Desktop/DS607/Assignment/A3/spam_or_not_spam_features.csv', header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = parameters2.iloc[:,0:57]\n",
    "y3 = parameters2.iloc[:,57]\n",
    "\n",
    "#   RandomTreeClassifier does not like NaN values in the data, so, all the NaN values are converted to 0.\n",
    "X3_e = np.nan_to_num (X3)\n",
    "y3_e = np.nan_to_num (y3)\n",
    "\n",
    "X3_tr, X3_te, y3_tr, y3_te = train_test_split (X3_e, y3_e, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M3 = RandomForestClassifier ()\n",
    "M3.fit (X3_tr, y3_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9483333333333334"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3_pred = M3.predict (X3_te)\n",
    "accuracy_score (y3_te, y3_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sms_span.csv and spam_or_not_spam.csv contained the messages (or emails), so pre-processing for word and character frequencies, and longest length, average length and sum of lengths of capital letters needed to be done prior to training a model. For sms_span.csv, spam and not spam was labeled using the terms 'spam' and 'ham', respectively, so they needed to be converted to 1 and 0. Spam_or_not_spam.csv were already labeled as 1 and 0.\n",
    "Spambase.csv already had all the pre-processing completed, so nothing needed to be done. \n",
    "Spam_or_not_spam.csv contained non-string entries, which caused errors with the regular expressions. So, exceptions needed to be made during pre-processing.\n",
    "\n",
    "The some of the emails in spam_or_not_spam contained none roman characters, for example the last message contained traditional chinese characters. This does not appear to have affected the analysis.\n",
    "\n",
    "After pre-processing, all three datasets had the same number of attributes (columns), spambase and spam_or_not_spam contain fewer entries (rows) than sms_span, and spam_or_not_spam contains fewer entries than the other two.\n",
    "* sms_spam: 5564 entries\n",
    "* spambase: 4601 entries\n",
    "* spam_or_not_spam: 3000 entries\n",
    "\n",
    "There was not a difference between training the models between each dataset.\n",
    "\n",
    "The accuracy of the models are similar, all three being around 95 %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9514824797843666"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   using sms_spam dataset\n",
    "\n",
    "MDT_1 = DecisionTreeClassifier ()\n",
    "MDT_1.fit (X_tr, y_tr)\n",
    "yDT_1_pred = MDT_1.predict (X_te)\n",
    "accuracy_score (y_te, yDT_1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9272529858849077"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   using spambase dataset\n",
    "\n",
    "MDT_2 = DecisionTreeClassifier ()\n",
    "MDT_2.fit (X2_tr, y2_tr)\n",
    "yDT_2_pred = MDT_2.predict (X2_te)\n",
    "accuracy_score (y2_te, yDT_2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9016666666666666"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   using spam_or_not_spam dataset\n",
    "\n",
    "MDT_3 = DecisionTreeClassifier ()\n",
    "MDT_3.fit (X3_tr, y3_tr)\n",
    "yDT_3_pred = MDT_3.predict (X3_te)\n",
    "accuracy_score (y3_te, yDT_3_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try k-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317160826594789"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   using sms_spam dataset\n",
    "\n",
    "MKN_1 = KNeighborsClassifier ()\n",
    "MKN_1.fit (X_tr, y_tr)\n",
    "yKN_1_pred = MKN_1.predict (X_te)\n",
    "accuracy_score (y_te, yKN_1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7915309446254072"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   using spambase dataset\n",
    "\n",
    "MKN_2 = KNeighborsClassifier ()\n",
    "MKN_2.fit (X2_tr, y2_tr)\n",
    "yKN_2_pred = MKN_2.predict (X2_te)\n",
    "accuracy_score (y2_te, yKN_2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   using spam_or_not_spam dataset\n",
    "\n",
    "MKN_3 = KNeighborsClassifier ()\n",
    "MKN_3.fit (X3_tr, y3_tr)\n",
    "yKN_3_pred = MKN_3.predict (X3_te)\n",
    "accuracy_score (y3_te, yKN_3_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ryan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8984725965858041"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   using sms_spam dataset\n",
    "\n",
    "MLR_1 = LogisticRegression ()\n",
    "MLR_1.fit (X_tr, y_tr)\n",
    "yLR_1_pred = MLR_1.predict (X_te)\n",
    "accuracy_score (y_te, yLR_1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ryan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9250814332247557"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   using spambase dataset\n",
    "\n",
    "MLR_2 = LogisticRegression ()\n",
    "MLR_2.fit (X2_tr, y2_tr)\n",
    "yLR_2_pred = MLR_2.predict (X2_te)\n",
    "accuracy_score (y2_te, yLR_2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ryan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7966666666666666"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   using spam_or_not_spam dataset\n",
    "\n",
    "MLR_3 = LogisticRegression ()\n",
    "MLR_3.fit (X3_tr, y3_tr)\n",
    "yLR_3_pred = MLR_3.predict (X3_te)\n",
    "accuracy_score (y3_te, yLR_3_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>k-Nearest Neighbours</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sms_spam.csv</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.951482</td>\n",
       "      <td>0.931716</td>\n",
       "      <td>0.898473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>spambase.csv</td>\n",
       "      <td>0.958740</td>\n",
       "      <td>0.927253</td>\n",
       "      <td>0.791531</td>\n",
       "      <td>0.925081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam_or_not_spam.csv</td>\n",
       "      <td>0.948333</td>\n",
       "      <td>0.901667</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.796667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dataset  Random Forest  Decision Tree  k-Nearest Neighbours  \\\n",
       "0          sms_spam.csv       0.968553       0.951482              0.931716   \n",
       "1          spambase.csv       0.958740       0.927253              0.791531   \n",
       "2  spam_or_not_spam.csv       0.948333       0.901667              0.820000   \n",
       "\n",
       "   Logistic Regression  \n",
       "0             0.898473  \n",
       "1             0.925081  \n",
       "2             0.796667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d3 = {'Dataset' : ['sms_spam.csv', 'spambase.csv', 'spam_or_not_spam.csv'], \n",
    "      'Random Forest' : [accuracy_score (y_te, y_pred), accuracy_score (y2_te, y2_pred), accuracy_score (y3_te, y3_pred)],\n",
    "     'Decision Tree' : [accuracy_score (y_te, yDT_1_pred), accuracy_score (y2_te, yDT_2_pred), accuracy_score (y3_te, yDT_3_pred)],\n",
    "     'k-Nearest Neighbours' : [accuracy_score (y_te, yKN_1_pred), accuracy_score (y2_te, yKN_2_pred), accuracy_score (y3_te, yKN_3_pred)],\n",
    "     'Logistic Regression' : [accuracy_score (y_te, yLR_1_pred), accuracy_score (y2_te, yLR_2_pred), accuracy_score (y3_te, yLR_3_pred)]}\n",
    "\n",
    "display (pd.DataFrame (d3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all three datasets, the Random Forest Classifier models provided higher accuracy than the other classifiers seen in class. The k-Nearest Neighbours Classifier models provided the least accurate prediction for spambase, and Logistic Regression had the least accurate predictions for sms_spam and spam_or_not_spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
